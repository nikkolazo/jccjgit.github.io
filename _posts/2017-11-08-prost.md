---
layout: post
title:  "Example: Prostate cancer"
date:   2017-11-08 18:46:59 -0300
categories: The Elements of Statistical Learning
---

Here we will review the example from section 3.2.1.

We begin by loading the relevant libraries

```python
import pandas as pd
from pandas.plotting import scatter_matrix
import statsmodels.formula.api as sm
import matplotlib.pyplot as plt
```
we then load the dataset and select the training data

```python
url =
"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"
names = ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45', 'lpsa', 'train']
dataset = pd.read_csv(url, delim_whitespace=True, skiprows=[0],
names=names)
trainDataset = dataset[dataset['train'] == 'T']
```

take a look at the data

```python
scatter_matrix(dataset)
plt.show()
```
{% for file in site.static_files %}
    {% if file.image %}
![{file.name}]({{file.path}})
    {% endif %}
{% endfor %}

and obtain the coefficients among other values

```python
mod = sm.ols(formula='lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45', data=trainDataset)
res = mod.fit()
print(res.summary())
```

```python
                            OLS Regression Results
==============================================================================
Dep. Variable:                   lpsa   R-squared:                       0.694
Model:                            OLS   Adj. R-squared:                  0.652
Method:                 Least Squares   F-statistic:                     16.47
Date:                Wed, 08 Nov 2017   Prob (F-statistic):           2.04e-12
Time:                        18:34:37   Log-Likelihood:                -67.505
No. Observations:                  67   AIC:                             153.0
Df Residuals:                      58   BIC:                             172.9
Df Model:                           8
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.4292      1.554      0.276      0.783      -2.681       3.539
lcavol         0.5765      0.107      5.366      0.000       0.361       0.792
lweight        0.6140      0.223      2.751      0.008       0.167       1.061
age           -0.0190      0.014     -1.396      0.168      -0.046       0.008
lbph           0.1448      0.070      2.056      0.044       0.004       0.286
svi            0.7372      0.299      2.469      0.017       0.140       1.335
lcp           -0.2063      0.111     -1.867      0.067      -0.428       0.015
gleason       -0.0295      0.201     -0.147      0.884      -0.432       0.373
pgg45          0.0095      0.005      1.738      0.088      -0.001       0.020
==============================================================================
Omnibus:                        0.825   Durbin-Watson:                   1.690
Prob(Omnibus):                  0.662   Jarque-Bera (JB):                0.389
Skew:                          -0.164   Prob(JB):                        0.823
Kurtosis:                       3.178   Cond. No.                     1.29e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is
correctly specified.
[2] The condition number is large, 1.29e+03. This might indicate that there
are strong multicollinearity or other numerical problems.
```
