---
layout: post
title:  "Example: Prostate cancer (OLS)"
date:   2017-11-08 18:46:59 -0300
categories: The-Elements-of-Statistical-Learning
---

Here we will review the example from section 3.2.1. For an overview of the methods, please refer to [Linear Methods for Regression (section 3.2).](https://github.com/jccjgit/notes-TEoSL/blob/master/linear-methods-for-regression/paper.pdf)

We begin by loading the relevant libraries

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from pandas.plotting import scatter_matrix
import statsmodels.formula.api as sm
import matplotlib.pyplot as plt
```
we then load the dataset and select the training data

```python
url =
"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"
names = ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45', 'lpsa', 'train']
dataset = pd.read_csv(url, delim_whitespace=True, skiprows=[0], names=names)
```

take a look at the data

```python
scatter_matrix(dataset)
plt.show()
```
![prostCancer_3_2_1_figure3_1](/figures/prostCancer_3_2_1_figure3_1.png)


Let's normalize it to have unit variance

```python
array = dataset.values[:, :9]
scaler = StandardScaler(with_mean=False).fit(array)
rescaled = scaler.transform(array)
```
select the training data

```python
rescaledTrain = rescaled[dataset['train'] == 'T']
trainData = pd.DataFrame(data=rescaledTrain, columns=names[0:9])
```
and fit the model

```python
mod = sm.ols(formula='lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45', data=trainData)
res = mod.fit()
print(res.summary())
```

```python
OLS Regression Results
==============================================================================
Dep. Variable:                   lpsa   R-squared:                       0.694
Model:                            OLS   Adj. R-squared:                  0.652
Method:                 Least Squares   F-statistic:                     16.47
Date:                Thu, 09 Nov 2017   Prob (F-statistic):           2.04e-12
Time:                        11:15:08   Log-Likelihood:                -58.236
No. Observations:                  67   AIC:                             134.5
Df Residuals:                      58   BIC:                             154.3
Df Model:                           8
Covariance Type:            nonrobust
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      0.3737      1.353      0.276      0.783      -2.334       3.082
lcavol         0.5887      0.110      5.366      0.000       0.369       0.808
lweight        0.2279      0.083      2.751      0.008       0.062       0.394
age           -0.1226      0.088     -1.396      0.168      -0.298       0.053
lbph           0.1821      0.089      2.056      0.044       0.005       0.359
svi            0.2644      0.107      2.469      0.017       0.050       0.479
lcp           -0.2499      0.134     -1.867      0.067      -0.518       0.018
gleason       -0.0185      0.126     -0.147      0.884      -0.270       0.233
pgg45          0.2313      0.133      1.738      0.088      -0.035       0.498
==============================================================================
Omnibus:                        0.825   Durbin-Watson:                   1.690
Prob(Omnibus):                  0.662   Jarque-Bera (JB):                0.389
Skew:                          -0.164   Prob(JB):                        0.823
Kurtosis:                       3.178   Cond. No.                         279.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is
correctly specified.
```
