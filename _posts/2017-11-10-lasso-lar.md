---
layout: post
title:  "Example: Prostate cancer (Lasso via LARS)"
date:   2017-11-10 17:35:59 -0300
categories: The-Elements-of-Statistical-Learning
---

![lassoLars](/figures/lassoLars.png)

Here we continue to review the example from section 3.2.1. This time we built its Lasso path using the LARS algorithm. For an overview of the methods, please refer to [Linear Methods for Regression (section 3.4).](https://github.com/jccjgit/notes-TEoSL/blob/master/linear-methods-for-regression/paper.pdf)

As usual, we first load the relevant libraries
```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import numpy as np
from sklearn import linear_model
```
we then load the dataset and select the training data

```python
url = "https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"
names = ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45', 'lpsa', 'train']
dataset = pd.read_csv(url, delim_whitespace=True, skiprows=[0], names=names)
```

```python
array = dataset.values[:, :9]
scaler = StandardScaler(with_mean=False).fit(array)
rescaled = scaler.transform(array)
```

```python
rescaledTrain = rescaled[dataset['train'] == 'T']
X = np.array(rescaledTrain[:, 0:8])
y = np.array(rescaledTrain[:, 8])
```
and implement the Ridge regression

and compute the regularization path using the LARS algorith
```python
alphas, _, coefs = linear_model.lars_path(X, y, method='lasso', verbose=True)

xx = np.sum(np.abs(coefs.T), axis=1)
xx /= xx[-1]

ax = plt.gca()
graphs = ax.plot(xx, coefs.T)
plt.legend(iter(graphs), names[:8])
ymin, ymax = plt.ylim()
plt.vlines(xx, ymin, ymax, linestyle='dashed')
plt.xlabel('|coef| / max|coef|')
plt.ylabel('Coefficients')
plt.title('LASSO Path')
plt.axis('tight')
plt.show()
```
