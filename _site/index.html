<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Latest Posts &#8211; Statistical Learning</title>
<meta name="description" content="Describe this nonsense.">
<meta name="keywords" content="Jekyll, theme, themes, responsive, blog, modern">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Latest Posts">
<meta property="og:description" content="Describe this nonsense.">
<meta property="og:url" content="https://jccjgit.github.io/">
<meta property="og:site_name" content="Statistical Learning">





<link rel="canonical" href="https://jccjgit.github.io/">
<link href="https://jccjgit.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Statistical Learning Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://jccjgit.github.io/assets/css/main.css">
<!-- Webfonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="https://jccjgit.github.io/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://jccjgit.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://jccjgit.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://jccjgit.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://jccjgit.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://jccjgit.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://jccjgit.github.io/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post-index" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="https://jccjgit.github.io/">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="https://jccjgit.github.io/images/avatar.jpg" alt="Juan Carlos Calvo Jackson photo" class="author-photo">
					<h4>Juan Carlos Calvo Jackson</h4>
					<p>Juan Carlos is a Oxon Cantab physicist and mathematician</p>
				</li>
				<li><a href="https://jccjgit.github.io/about/"><span class="btn btn-inverse">Learn More</span></a></li>
				<li>
					<a href="mailto:juancarlos.calvojackson@gmail.com"><i class="fa fa-fw fa-envelope"></i> Email</a>
				</li>
				
				
				
				<li>
					<a href="https://linkedin.com/in/https://www.linkedin.com/in/jc-cj"><i class="fa fa-fw fa-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="https://github.com/https://github.com/jccjgit"><i class="fa fa-fw fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="https://jccjgit.github.io/posts/">All Posts</a></li>
				<li><a href="https://jccjgit.github.io/tags/">All Tags</a></li>
			</ul>
		</li>
		
	    
	    <li><a href="https://jccjgit.github.io/notes/" >Notes</a></li>
	  
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Statistical Learning</h1>
      <h2>Latest Posts</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2017-11-10T17:35:59-03:00"><a href="https://jccjgit.github.io/ridge/">November 10, 2017</a></time></span><span class="author vcard"><span class="fn"><a href="https://jccjgit.github.io/about/" title="About Juan Carlos Calvo Jackson">Juan Carlos Calvo Jackson</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="https://jccjgit.github.io/ridge/" rel="bookmark" title="Example: Prostate cancer (Ridge)" itemprop="url">Example: Prostate cancer (Ridge)</a></h1>
    
  </header>
  <div class="entry-content">
    <p><img src="/images/ridgeRegression_figure6_1.png" alt="ridgeRegression_figure6_1" /></p>

<p>Here we continue to review the example from section 3.2.1. This time we apply Ridge regression to it. For an overview of the methods, please refer to <a href="https://github.com/jccjgit/notes-TEoSL/blob/master/linear-methods-for-regression/paper.pdf">Linear Methods for Regression (section 3.4).</a></p>

<p>As usual, we first load the relevant libraries</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">somefunctions</span> <span class="kn">as</span> <span class="nn">sf</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
</code></pre>
</div>
<p>we then load the dataset and select the training data</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">url</span> <span class="o">=</span> <span class="s">"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lcavol'</span><span class="p">,</span> <span class="s">'lweight'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'lbph'</span><span class="p">,</span> <span class="s">'svi'</span><span class="p">,</span> <span class="s">'lcp'</span><span class="p">,</span> <span class="s">'gleason'</span><span class="p">,</span> <span class="s">'pgg45'</span><span class="p">,</span> <span class="s">'lpsa'</span><span class="p">,</span> <span class="s">'train'</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">array</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">9</span><span class="p">]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
<span class="n">rescaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">rescaledTrain</span> <span class="o">=</span> <span class="n">rescaled</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="s">'train'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'T'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rescaledTrain</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rescaledTrain</span><span class="p">[:,</span> <span class="mi">8</span><span class="p">])</span>
</code></pre>
</div>
<p>and implement the Ridge regression</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">n_alphas</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">n_alphas</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">SomeFunctions</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">la</span><span class="p">):</span>
    <span class="s">"""Edof."""</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">effectiveDofF</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">la</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>


<span class="n">vfunc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="n">dof</span> <span class="o">=</span> <span class="n">vfunc</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
    <span class="n">ridge</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</code></pre>
</div>

<p>The results are graphed as follows</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">lob</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dof</span><span class="p">,</span> <span class="n">coefs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">lob</span><span class="p">),</span> <span class="n">names</span><span class="p">[:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'degrees of freedom'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'coefficients'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Ridge coefficients as a function of the degrees of freedom'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'tight'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2017-11-10T17:35:59-03:00"><a href="https://jccjgit.github.io/lasso-lar/">November 10, 2017</a></time></span><span class="author vcard"><span class="fn"><a href="https://jccjgit.github.io/about/" title="About Juan Carlos Calvo Jackson">Juan Carlos Calvo Jackson</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="https://jccjgit.github.io/lasso-lar/" rel="bookmark" title="Example: Prostate cancer (Lasso via LARS)" itemprop="url">Example: Prostate cancer (Lasso via LARS)</a></h1>
    
  </header>
  <div class="entry-content">
    <p><img src="/images/lassoLars.png" alt="lassoLars" /></p>

<p>Here we continue to review the example from section 3.2.1. This time we built its Lasso path using the LARS algorithm. For an overview of the methods, please refer to <a href="https://github.com/jccjgit/notes-TEoSL/blob/master/linear-methods-for-regression/paper.pdf">Linear Methods for Regression (section 3.4).</a></p>

<p>As usual, we first load the relevant libraries</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
</code></pre>
</div>
<p>we then load the dataset and select the training data</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">url</span> <span class="o">=</span> <span class="s">"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lcavol'</span><span class="p">,</span> <span class="s">'lweight'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'lbph'</span><span class="p">,</span> <span class="s">'svi'</span><span class="p">,</span> <span class="s">'lcp'</span><span class="p">,</span> <span class="s">'gleason'</span><span class="p">,</span> <span class="s">'pgg45'</span><span class="p">,</span> <span class="s">'lpsa'</span><span class="p">,</span> <span class="s">'train'</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">array</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">9</span><span class="p">]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
<span class="n">rescaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">rescaledTrain</span> <span class="o">=</span> <span class="n">rescaled</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="s">'train'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'T'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rescaledTrain</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rescaledTrain</span><span class="p">[:,</span> <span class="mi">8</span><span class="p">])</span>
</code></pre>
</div>

<p>and compute the regularization path using the LARS algorith</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">alphas</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">coefs</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">lars_path</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">'lasso'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">coefs</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">/=</span> <span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">graphs</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">coefs</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">graphs</span><span class="p">),</span> <span class="n">names</span><span class="p">[:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'dashed'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'|coef| / max|coef|'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Coefficients'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'LASSO Path'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'tight'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2017-11-08T18:46:59-03:00"><a href="https://jccjgit.github.io/prost/">November 08, 2017</a></time></span><span class="author vcard"><span class="fn"><a href="https://jccjgit.github.io/about/" title="About Juan Carlos Calvo Jackson">Juan Carlos Calvo Jackson</a></span></span>
      
      <span class="entry-reading-time">
        <i class="fa fa-clock-o"></i>
        
Reading time ~1 minute
      </span><!-- /.entry-reading-time -->
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="https://jccjgit.github.io/prost/" rel="bookmark" title="Example: Prostate cancer (OLS)" itemprop="url">Example: Prostate cancer (OLS)</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Here we will review the example from section 3.2.1. For an overview of the methods, please refer to <a href="https://github.com/jccjgit/notes-TEoSL/blob/master/linear-methods-for-regression/paper.pdf">Linear Methods for Regression (section 3.2).</a></p>

<p>We begin by loading the relevant libraries</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">pandas.plotting</span> <span class="kn">import</span> <span class="n">scatter_matrix</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</code></pre>
</div>
<p>we then load the dataset and select the training data</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">url</span> <span class="o">=</span>
<span class="s">"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data"</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lcavol'</span><span class="p">,</span> <span class="s">'lweight'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'lbph'</span><span class="p">,</span> <span class="s">'svi'</span><span class="p">,</span> <span class="s">'lcp'</span><span class="p">,</span> <span class="s">'gleason'</span><span class="p">,</span> <span class="s">'pgg45'</span><span class="p">,</span> <span class="s">'lpsa'</span><span class="p">,</span> <span class="s">'train'</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
</code></pre>
</div>

<p>take a look at the data</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>
<p><img src="/images/prostCancer_3_2_1_figure3_1.png" alt="prostCancer_3_2_1_figure3_1" /></p>

<p>Letâ€™s normalize it to have unit variance</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">array</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">9</span><span class="p">]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
<span class="n">rescaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
</code></pre>
</div>
<p>select the training data</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">rescaledTrain</span> <span class="o">=</span> <span class="n">rescaled</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="s">'train'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'T'</span><span class="p">]</span>
<span class="n">trainData</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">rescaledTrain</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">9</span><span class="p">])</span>
</code></pre>
</div>
<p>and fit the model</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">mod</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s">'lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">trainData</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</code></pre>
</div>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>                   <span class="n">lpsa</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                       <span class="mf">0.694</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                  <span class="mf">0.652</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                     <span class="mf">16.47</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Thu</span><span class="p">,</span> <span class="mi">09</span> <span class="n">Nov</span> <span class="mi">2017</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>           <span class="mf">2.04e-12</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">11</span><span class="p">:</span><span class="mi">15</span><span class="p">:</span><span class="mi">08</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                <span class="o">-</span><span class="mf">58.236</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">67</span>   <span class="n">AIC</span><span class="p">:</span>                             <span class="mf">134.5</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">58</span>   <span class="n">BIC</span><span class="p">:</span>                             <span class="mf">154.3</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">8</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">Intercept</span>      <span class="mf">0.3737</span>      <span class="mf">1.353</span>      <span class="mf">0.276</span>      <span class="mf">0.783</span>      <span class="o">-</span><span class="mf">2.334</span>       <span class="mf">3.082</span>
<span class="n">lcavol</span>         <span class="mf">0.5887</span>      <span class="mf">0.110</span>      <span class="mf">5.366</span>      <span class="mf">0.000</span>       <span class="mf">0.369</span>       <span class="mf">0.808</span>
<span class="n">lweight</span>        <span class="mf">0.2279</span>      <span class="mf">0.083</span>      <span class="mf">2.751</span>      <span class="mf">0.008</span>       <span class="mf">0.062</span>       <span class="mf">0.394</span>
<span class="n">age</span>           <span class="o">-</span><span class="mf">0.1226</span>      <span class="mf">0.088</span>     <span class="o">-</span><span class="mf">1.396</span>      <span class="mf">0.168</span>      <span class="o">-</span><span class="mf">0.298</span>       <span class="mf">0.053</span>
<span class="n">lbph</span>           <span class="mf">0.1821</span>      <span class="mf">0.089</span>      <span class="mf">2.056</span>      <span class="mf">0.044</span>       <span class="mf">0.005</span>       <span class="mf">0.359</span>
<span class="n">svi</span>            <span class="mf">0.2644</span>      <span class="mf">0.107</span>      <span class="mf">2.469</span>      <span class="mf">0.017</span>       <span class="mf">0.050</span>       <span class="mf">0.479</span>
<span class="n">lcp</span>           <span class="o">-</span><span class="mf">0.2499</span>      <span class="mf">0.134</span>     <span class="o">-</span><span class="mf">1.867</span>      <span class="mf">0.067</span>      <span class="o">-</span><span class="mf">0.518</span>       <span class="mf">0.018</span>
<span class="n">gleason</span>       <span class="o">-</span><span class="mf">0.0185</span>      <span class="mf">0.126</span>     <span class="o">-</span><span class="mf">0.147</span>      <span class="mf">0.884</span>      <span class="o">-</span><span class="mf">0.270</span>       <span class="mf">0.233</span>
<span class="n">pgg45</span>          <span class="mf">0.2313</span>      <span class="mf">0.133</span>      <span class="mf">1.738</span>      <span class="mf">0.088</span>      <span class="o">-</span><span class="mf">0.035</span>       <span class="mf">0.498</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">0.825</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">1.690</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.662</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">0.389</span>
<span class="n">Skew</span><span class="p">:</span>                          <span class="o">-</span><span class="mf">0.164</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.823</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">3.178</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                         <span class="mf">279.</span>
<span class="o">==============================================================================</span>

<span class="n">Warnings</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span>
<span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
</code></pre>
</div>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->




</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2017 Juan Carlos Calvo Jackson. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/hpstr-jekyll-theme/" rel="nofollow">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://jccjgit.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://jccjgit.github.io/assets/js/scripts.min.js"></script>



          

</body>
</html>